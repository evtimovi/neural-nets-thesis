# neural-nets-thesis
This is a repository for the code work to be performed as part of a senior thesis at Lafayette College under the supervision of Professor Amir Sadovnik.

The folder basic-mnist contains implementations of the neural network that will be trained to recognize digits from the MNIST data set. These follow the TensorFlow tutorials [here](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html) and [here](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html#deep-mnist-for-experts).

The folder `foo` contains various scripts that are used to run and train the networks and/or perform various experiments on them. For example, a script that runs the VGG face networkand then computes its accuracy is contained in `foo/measure_accuracy.py`.
The intro comment in the script contains details but it can be run with this command: ``python measure_accuracy.py lfw/ pairsDevTest.txt``

Generally, these scripts are meant to be copied into the root folder of the repo and run from there (so that they can find the various Python packages described below).

The folder `vggface` contains an implementation of the VGG neural network used for facial recognition.
This folder is organized into a Python package structure and further the different networks are objects.
So to invoke any particular implementation (or rather generate an instance of that object), one needs to `from vggface import networks as vggn` and then call, for example, `vggn.VGGFaceVanilla()` for an instance of a plain vanilla implementation of VGGFace. 
The researchers who developed the network are O.M. Parkhi, A. Vedaldi, and A. Zisserman and their paper was called Deep Face Recognition (published in 2015 in the British Machine Vision Conference). Their work carries a [Creative Commons Attribution License](https://creativecommons.org/licenses/by-nc/4.0/legalcode).  
The code for implementing the network in tensorflow is available on GitHub [here](https://github.com/AKSHAYUBHAT/TensorFace). Additional modifications were done by Wassim Gharbi'19 at Lafayette College.

The folder `util` contains various utility modules which are NOT written in an object oriented fashion. 
Rather, they are split into various functions. 
So, in order to use the different performance measures, one needs to invoke `from util import performance p` and then call them by writing `p.fnmr(...)`


The primary work of this thesis is focused in the `train_meb.py` and `evaluate_meb.py` files. They feed their parameters from `train_params.py`. The research is on finding a way to protect the biometric face templates generated by the neural network. So far the goal has been to reimplement the work done by Rohit Pandey, Yingbo Zhou, and Venu Govindaraju in ["Deep Secure Encoding: An Application to Face Recognition"](https://arxiv.org/abs/1506.04340).

Additional work was later performed in the other python scripts available in the root. Instead of performing the evaluation in Python, the goal of these files was to generate all possible outputs from the VGG network or the VGG network with the extra MEB layer and output them for analysis in other programs (as .csv files). The files beginning with `all*` serve this purpose.
Another set of scripts, in the `howfar*` files, compute distances between a target image code and a code produced by the network. The end suffixes of both the `howfar*` and `all*` files indicate the network setup - whether it is the plain VGG, the VGG with an added layer with and without normalization. 

Two folders are not committed: `datasets` where the images used in the network live and `output` where weights are saved during training and other output files are recorded during evaluation.

